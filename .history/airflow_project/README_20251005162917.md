# Energy Data Quality ETL Project (Apache Airflow)

## Project Overview
This project demonstrates an end-to-end ETL pipeline using Apache Airflow to evaluate and improve data quality for energy consumption data. It integrates multiple heterogeneous sources (Paris, Ã‰vry, CSP, IRIS) into unified target tables, with a focus on data quality.

## Data Sources & Schemas
- **Population_Paris / Population_Evry**: `ID_Personne, Nom, Prenom, Adresse, CSP`
- **Consommation_Paris / Consommation_Evry**: `ID_Adr, N, Nom_Rue, Code_Postal, NB_KW_Jour`
- **CSP**: `ID_CSP, Desc, Salaire_Moyen, Salaire_Min, Salaire_Max`
- **IRIS**: `ID_Rue, ID_Ville, ID_IRIS`

## Airflow DAG Structure
- **Extract**: Loads raw CSV data for each source.
- **Evaluate Quality**: Checks completeness, duplicates, and format consistency.
- **Clean & Transform**:
  - Normalize CSP codes
  - Remove duplicates
  - Fill/flag missing data
  - Algebraic operations (e.g., average consumption by IRIS/CSP)
- **Join & Aggregate**:
  - Joins Population, Consommation, and IRIS
  - Produces target tables:
    - `Consommation_IRIS_Paris(ID_IRIS, Conso_moyenne_annuelle)`
    - `Consommation_IRIS_Evry(ID_IRIS, Conso_moyenne_annuelle)`
    - `Consommation_CSP(ID_CSP, Conso_moyenne_annuelle, Salaire_Moyen)`
- **Load**: Saves cleaned/integrated data to CSV (or PostgreSQL)

## Mapping & Join Logic
- Population and Consommation are joined on address fields.
- IRIS is joined using street/ID_Rue.
- Aggregation is performed by IRIS and CSP.

## Data Quality Checks
Implemented in `utils/quality_checks.py`:
- Completeness (missing values)
- Duplicates
- Format consistency
- Aggregated in a report

## How to Run Locally
1. **Install Requirements**
   ```bash
   pip install -r requirements.txt
   ```
2. **Start Airflow (with Docker Compose recommended)**
   - Use the official [Airflow Docker Compose setup](https://airflow.apache.org/docs/apache-airflow/stable/howto/docker-compose/index.html)
   - Mount the `airflow_project` folder to `/opt/airflow` in your Docker Compose file.
3. **Trigger the DAG**
   - Access Airflow UI at `localhost:8080`
   - Trigger the `energy_quality_etl` DAG

## Output
- Cleaned and integrated data is saved in `output/`:
  - `consommation_iris_paris.csv`
  - `consommation_iris_evry.csv`
  - `consommation_csp.csv`

## Notes
- The project uses synthetic data for demonstration.
- All transformations are performed with Pandas in PythonOperator tasks.
- Data quality checks are extensible for further rules.
