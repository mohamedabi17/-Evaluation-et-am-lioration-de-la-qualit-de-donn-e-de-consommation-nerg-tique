# Projet ETL QualitÃ© des DonnÃ©es Ã‰nergÃ©tiques (Apache Airflow)

## ğŸ¯ Objectif du Projet
Ce projet dÃ©montre un pipeline ETL complet utilisant Apache Airflow pour **Ã©valuer et amÃ©liorer la qualitÃ© des donnÃ©es** de consommation Ã©nergÃ©tique. Il intÃ¨gre plusieurs sources hÃ©tÃ©rogÃ¨nes (Paris, Ã‰vry, CSP, IRIS) dans des tables cibles unifiÃ©es, avec un focus sur la qualitÃ© des donnÃ©es.

## ğŸ“Š SchÃ©ma Cible
- **Consommation_IRIS_Paris** : `(ID_IRIS, Conso_moyenne_annuelle)`
- **Consommation_IRIS_Evry** : `(ID_IRIS, Conso_moyenne_annuelle)`
- **Consommation_CSP** : `(ID_CSP, Conso_moyenne_annuelle, Salaire_Moyen)`

## ğŸ“ Sources de DonnÃ©es

### Source S1 â€“ DonnÃ©es Paris
- **Population** : `(ID_Personne, Nom, PrÃ©nom, Adresse, CSP)`
- **Consommation** : `(ID_Adr, N, Nom_Rue, Code_Postal, NB_KW_Jour)`

### Source S2 â€“ DonnÃ©es Ã‰vry
- **Population** : `(ID_Personne, Nom, PrÃ©nom, Adresse, CSP)`
- **Consommation** : `(ID_Adr, N, Nom_Rue, Code_Postal, NB_KW_Jour)`

### Source S3 â€“ CatÃ©gories Socio-Professionnelles
- **CSP** : `(ID_CSP, Desc, Salaire_Moyen, Salaire_Min, Salaire_Max)`

### Source S4 â€“ IRIS (Ãlots RegroupÃ©s pour l'Information Statistique)
- **IRIS** : `(ID_Rue, ID_Ville, ID_IRIS)`

## ğŸ” Ã‰valuation de la QualitÃ© des DonnÃ©es

Le systÃ¨me Ã©value automatiquement plusieurs dimensions de qualitÃ© :

### 1. **ConformitÃ© Ã  un Format/Codification**
- Validation des codes CSP (1, 2, 3, 4)
- VÃ©rification des formats numÃ©riques
- Consistance des codes postaux par ville

### 2. **HÃ©tÃ©rogÃ©nÃ©itÃ© des Ã‰chelles/GranularitÃ©**
- Analyse de la distribution des donnÃ©es par groupe
- DÃ©tection d'incohÃ©rences de granularitÃ©
- Normalisation des unitÃ©s de mesure

### 3. **ComplÃ©tude des DonnÃ©es**
- Calcul du pourcentage de valeurs manquantes par colonne
- Score de complÃ©tude global
- StratÃ©gies de comblement des lacunes

### 4. **DÃ©tection et Ã‰limination de Doublons**
- Identification des lignes dupliquÃ©es
- Calcul du score d'unicitÃ©
- Suppression intelligente des doublons

## ğŸ—ï¸ Structure du DAG Airflow

```
ğŸ“‹ energy_data_quality_etl
â”œâ”€â”€ ğŸ“¤ Extraction des sources (4 sources)
â”œâ”€â”€ ğŸ” Ã‰valuation qualitÃ© (mÃ©triques + visualisations)
â”œâ”€â”€ ğŸ”€ DÃ©cision stratÃ©gie nettoyage
â”œâ”€â”€ ğŸ§¹ AmÃ©lioration qualitÃ© (si nÃ©cessaire)
â”œâ”€â”€ ğŸ”— IntÃ©gration donnÃ©es
â””â”€â”€ ğŸ“Š Rapport final
```

### DÃ©tail des TÃ¢ches

1. **Extraction** : Chargement des CSV sources avec statistiques
2. **Ã‰valuation QualitÃ©** : 
   - GÃ©nÃ©ration de rapports JSON dÃ©taillÃ©s
   - CrÃ©ation de visualisations (dashboards)
   - Calcul de scores par dimension
3. **StratÃ©gie Conditionnelle** : Branchement automatique selon la qualitÃ©
4. **AmÃ©lioration** : Application de rÃ¨gles de nettoyage spÃ©cifiques
5. **IntÃ©gration** : Jointures et agrÃ©gations vers les tables cibles
6. **Reporting** : SynthÃ¨se globale et mÃ©triques finales

## ğŸ“ˆ MÃ©triques et Visualisations

Le systÃ¨me gÃ©nÃ¨re automatiquement :

- **Dashboards qualitÃ©** : Graphiques de complÃ©tude, distribution des erreurs
- **Rapports JSON** : MÃ©triques dÃ©taillÃ©es par source et dimension
- **Scores globaux** : Note de qualitÃ© de 0 Ã  100 avec niveau (Excellent, Bon, Moyen, Faible)
- **Logs d'amÃ©lioration** : TraÃ§abilitÃ© des corrections appliquÃ©es

## ğŸš€ Comment ExÃ©cuter le Projet

### PrÃ©requis
- Docker et Docker Compose
- 4GB RAM minimum
- 2 CPU minimum

### DÃ©marrage Rapide

1. **Cloner et naviguer dans le projet**
   ```bash
   cd airflow_project
   ```

2. **Initialiser Airflow avec Docker**
   ```bash
   docker-compose up airflow-init
   ```

3. **DÃ©marrer les services**
   ```bash
   docker-compose up -d
   ```

4. **AccÃ©der Ã  l'interface Airflow**
   - URL : http://localhost:8080
   - Login : admin / admin123

5. **DÃ©clencher le DAG**
   - Naviguer vers "energy_data_quality_etl"
   - Cliquer sur "Trigger DAG"

### Alternative : Installation Locale

```bash
pip install -r requirements.txt
export AIRFLOW_HOME=$(pwd)
airflow db init
airflow users create --username admin --password admin --firstname Admin --lastname User --role Admin --email admin@example.com
airflow webserver --port 8080 &
airflow scheduler &
```

## ğŸ“‚ Structure du Projet

```
airflow_project/
â”œâ”€â”€ dags/
â”‚   â””â”€â”€ energy_quality_etl.py          # DAG principal
â”œâ”€â”€ sources/                           # DonnÃ©es sources (avec dÃ©fauts)
â”‚   â”œâ”€â”€ population_paris.csv
â”‚   â”œâ”€â”€ population_evry.csv
â”‚   â”œâ”€â”€ consommation_paris.csv
â”‚   â”œâ”€â”€ consommation_evry.csv
â”‚   â”œâ”€â”€ csp.csv
â”‚   â””â”€â”€ iris.csv
â”œâ”€â”€ output/                           # DonnÃ©es nettoyÃ©es et tables cibles
â”‚   â”œâ”€â”€ consommation_iris_paris.csv
â”‚   â”œâ”€â”€ consommation_iris_evry.csv
â”‚   â””â”€â”€ consommation_csp.csv
â”œâ”€â”€ quality_reports/                  # Rapports qualitÃ© JSON
â”œâ”€â”€ visualizations/                   # Graphiques et dashboards
â”œâ”€â”€ utils/
â”‚   â”œâ”€â”€ quality_checks.py            # Outils d'Ã©valuation qualitÃ©
â”‚   â””â”€â”€ data_quality_improver.py     # Outils d'amÃ©lioration
â”œâ”€â”€ docker-compose.yml               # Configuration Docker
â”œâ”€â”€ requirements.txt
â””â”€â”€ README.md
```

## ğŸ”§ Logique de Transformation

### Jointures et AgrÃ©gations

1. **Population + Consommation** : Jointure sur les adresses/IDs
2. **+ IRIS** : Enrichissement gÃ©ographique par rue
3. **AgrÃ©gation par IRIS** : Calcul de consommation moyenne par zone
4. **AgrÃ©gation par CSP** : Analyse sociologique + salaires moyens

### OpÃ©rations AlgÃ©briques

- **Moyenne de consommation** : `SUM(NB_KW_Jour) / COUNT(*) * 365` (annualisation)
- **Score de qualitÃ©** : Moyenne pondÃ©rÃ©e des dimensions (ComplÃ©tude 30%, UnicitÃ© 25%, Format 25%, Codification 20%)
- **Normalisation CSP** : Mapping textuel vers codes numÃ©riques

## ğŸ¯ AmÃ©liorations de QualitÃ© ImplÃ©mentÃ©es

### ComplÃ©tude
- Valeurs manquantes â†’ StratÃ©gies adaptÃ©es (moyenne, mode, valeurs par dÃ©faut)
- TraÃ§abilitÃ© des imputations

### ConformitÃ©
- Codes CSP invalides â†’ Normalisation automatique
- Formats incohÃ©rents â†’ Standardisation (TitleCase, numeric)

### UnicitÃ©
- Doublons exacts â†’ Suppression avec keep='first'
- Log du nombre de lignes supprimÃ©es

### Codification
- Mapping CSP texte/numÃ©rique : `{cadre: 1, employÃ©: 2, ouvrier: 3, retraitÃ©: 4}`
- Validation des codes postaux par ville

## ğŸ“Š InterprÃ©tation des RÃ©sultats

- **Score > 90%** : QualitÃ© Excellente âœ…
- **Score 80-90%** : QualitÃ© Bonne ğŸŸ¢  
- **Score 70-80%** : QualitÃ© Correcte ğŸŸ¡
- **Score < 70%** : QualitÃ© Insuffisante ğŸ”´ (nettoyage automatique)

## ğŸ” Monitoring et Logs

Tous les traitements sont loggÃ©s avec :
- Horodatage des opÃ©rations
- Nombre de lignes affectÃ©es
- DÃ©tail des corrections appliquÃ©es
- MÃ©triques avant/aprÃ¨s amÃ©lioration

## ğŸ› ï¸ Extensions Possibles

- IntÃ©gration PostgreSQL pour persistance
- Alertes automatiques sur dÃ©gradation qualitÃ©
- API REST pour consultation des mÃ©triques
- IntÃ©gration avec outils BI (Tableau, PowerBI)
- Tests unitaires et validation de schema

---
*Projet dÃ©veloppÃ© pour dÃ©montrer les meilleures pratiques ETL avec focus qualitÃ© des donnÃ©es*
