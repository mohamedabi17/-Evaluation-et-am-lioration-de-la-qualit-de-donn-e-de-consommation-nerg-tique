#!/usr/bin/env python3
"""
G√©n√©rateur de donn√©es synth√©tiques en grande quantit√© pour le projet ETL
Ce script g√©n√®re des datasets volumineux avec des probl√®mes de qualit√© r√©alistes
"""

import pandas as pd
import numpy as np
import random
from datetime import datetime, timedelta
import os

# Configuration
POPULATION_SIZE_PARIS = 50000
POPULATION_SIZE_EVRY = 25000
CONSUMPTION_RECORDS_PARIS = 75000
CONSUMPTION_RECORDS_EVRY = 35000
CSP_CATEGORIES = 8
IRIS_ZONES_PARIS = 150
IRIS_ZONES_EVRY = 80

# Donn√©es de r√©f√©rence fran√ßaises
NOMS_FRANCAIS = [
    "Martin", "Bernard", "Dubois", "Thomas", "Robert", "Richard", "Petit", "Durand",
    "Leroy", "Moreau", "Simon", "Laurent", "Lefebvre", "Michel", "Garcia", "David",
    "Bertrand", "Roux", "Vincent", "Fournier", "Morel", "Girard", "Andre", "Lefevre",
    "Mercier", "Dupont", "Lambert", "Bonnet", "Francois", "Martinez", "Legrand", "Garnier",
    "Faure", "Rousseau", "Blanc", "Guerin", "Muller", "Henry", "Roussel", "Nicolas",
    "Perrin", "Morin", "Mathieu", "Clement", "Gauthier", "Dumont", "Lopez", "Fontaine",
    "Chevalier", "Robin", "Masson", "Sanchez", "Gerard", "Nguyen", "Boyer", "Denis",
    "Lemaire", "Duval", "Joly", "Gautier", "Roger", "Roche", "Roy", "Noel"
]

PRENOMS_FRANCAIS = [
    "Jean", "Marie", "Michel", "Alain", "Patrick", "Pierre", "Philippe", "Christophe",
    "Daniel", "Bernard", "Nicolas", "Laurent", "Thierry", "Eric", "Frederic", "David",
    "Stephane", "Pascal", "Olivier", "Julien", "Sebastien", "Fabrice", "Bruno", "Vincent",
    "Sylvie", "Isabelle", "Catherine", "Francoise", "Monique", "Nathalie", "Valerie", "Sandrine",
    "Martine", "Nicole", "Veronique", "Christine", "Brigitte", "Dominique", "Chantal", "Jacqueline",
    "Anne", "Francine", "Karine", "Corinne", "Pascale", "Aurelie", "Celine", "Emilie",
    "Julie", "Laetitia", "Stephanie", "Sophie", "Delphine", "Caroline", "Virginie", "Marianne",
    "Claire", "Emma", "Camille", "Lea", "Manon", "Lisa", "Sarah", "Oceane"
]

RUES_PARIS = [
    "Rue de Rivoli", "Avenue des Champs-Elys√©es", "Boulevard Saint-Germain", "Rue de la Paix",
    "Avenue Montaigne", "Rue du Faubourg Saint-Honor√©", "Boulevard Haussmann", "Rue Lafayette",
    "Avenue Victor Hugo", "Rue Saint-Antoine", "Boulevard Voltaire", "Rue de Belleville",
    "Avenue de la R√©publique", "Rue Oberkampf", "Boulevard de Magenta", "Rue de Charonne",
    "Avenue Parmentier", "Rue du Temple", "Boulevard Beaumarchais", "Rue de M√©nilmontant",
    "Avenue Ledru-Rollin", "Rue de la Roquette", "Boulevard Richard-Lenoir", "Rue Saint-Maur",
    "Avenue Philippe-Auguste", "Rue de la Folie-M√©ricourt", "Boulevard Jules Ferry", "Rue Amelot",
    "Avenue de la Bastille", "Rue Popincourt", "Boulevard du Temple", "Rue Jean-Pierre Timbaud",
    "Avenue Trudaine", "Rue des Martyrs", "Boulevard de Rochechouart", "Rue Condorcet",
    "Avenue de Clichy", "Rue Blanche", "Boulevard des Batignolles", "Rue de Rome",
    "Avenue de Wagram", "Rue de L√©vis", "Boulevard Malesherbes", "Rue de Courcelles",
    "Avenue Hoche", "Rue de Prony", "Boulevard Pereire", "Rue Cardinet"
]

RUES_EVRY = [
    "Rue de l'Essonne", "Avenue de la Gare", "Boulevard des Champs", "Rue de la R√©publique",
    "Avenue du Parc", "Boulevard Libert√©", "Avenue Jean Jaur√®s", "Rue Nationale",
    "Avenue Fran√ßois Mitterrand", "Rue du Commerce", "Boulevard de la Paix", "Avenue de l'Europe",
    "Rue des √âcoles", "Avenue du G√©n√©ral de Gaulle", "Boulevard Victor Hugo", "Rue Pasteur",
    "Avenue Carnot", "Rue Gambetta", "Boulevard Clemenceau", "Avenue Foch",
    "Rue de la Mairie", "Avenue des Tilleuls", "Boulevard des Platanes", "Rue des Roses",
    "Avenue des Lilas", "Rue du Stade", "Boulevard des Sports", "Avenue de la Poste",
    "Rue de l'√âglise", "Avenue des √âcoles", "Boulevard de l'H√¥pital", "Rue de la Gendarmerie"
]

CODES_POSTAUX_PARIS = [
    75001, 75002, 75003, 75004, 75005, 75006, 75007, 75008, 75009, 75010,
    75011, 75012, 75013, 75014, 75015, 75016, 75017, 75018, 75019, 75020
]

CSP_DESCRIPTIONS = [
    "Agriculteurs exploitants",
    "Artisans, commer√ßants et chefs d'entreprise", 
    "Cadres et professions intellectuelles sup√©rieures",
    "Professions interm√©diaires",
    "Employ√©s",
    "Ouvriers",
    "Retrait√©s",
    "Autres personnes sans activit√© professionnelle"
]

def generate_population_data(city, size):
    """G√©n√©rer des donn√©es de population avec des probl√®mes de qualit√©."""
    
    print(f"üìä G√©n√©ration de {size:,} habitants pour {city}...")
    
    data = []
    
    for i in range(1, size + 1):
        # ID s√©quentiel avec offset par ville
        if city.lower() == "paris":
            id_personne = i
        else:
            id_personne = 100000 + i
        
        # Noms avec quelques valeurs manquantes (2%)
        nom = random.choice(NOMS_FRANCAIS) if random.random() > 0.02 else None
        
        # Pr√©noms avec quelques valeurs manquantes (1.5%)
        prenom = random.choice(PRENOMS_FRANCAIS) if random.random() > 0.015 else None
        
        # Adresses
        if city.lower() == "paris":
            rue = random.choice(RUES_PARIS)
            numero = random.randint(1, 200)
        else:
            rue = random.choice(RUES_EVRY)
            numero = random.randint(1, 150)
        
        # Adresse compl√®te avec quelques valeurs manquantes (1%)
        if random.random() > 0.01:
            adresse = f"{numero} {rue}"
        else:
            adresse = None
        
        # CSP avec diff√©rents formats pour cr√©er des probl√®mes de codification
        csp_choice = random.random()
        if csp_choice < 0.7:  # 70% codes num√©riques corrects
            csp = str(random.randint(1, 8))
        elif csp_choice < 0.85:  # 15% codes textuels
            csp_mapping = {
                1: "cadre", 2: "employ√©", 3: "ouvrier", 4: "retrait√©",
                5: "artisan", 6: "profession_intermediaire", 7: "agriculteur", 8: "sans_activite"
            }
            csp = csp_mapping[random.randint(1, 8)]
        elif csp_choice < 0.95:  # 10% codes invalides
            invalid_codes = ["9", "X", "NC", "0", "99", "cadres", "employes"]
            csp = random.choice(invalid_codes)
        else:  # 5% valeurs manquantes
            csp = None
        
        data.append({
            'ID_Personne': id_personne,
            'Nom': nom,
            'Prenom': prenom,
            'Adresse': adresse,
            'CSP': csp
        })
        
        # Progress indicator
        if i % 10000 == 0:
            print(f"  ‚úì {i:,} habitants g√©n√©r√©s...")
    
    # Ajouter des doublons intentionnels (3%)
    duplicates_count = int(size * 0.03)
    print(f"  üîÑ Ajout de {duplicates_count:,} doublons...")
    
    for _ in range(duplicates_count):
        original_row = random.choice(data)
        duplicate = original_row.copy()
        # Petites variations pour simuler des doublons "presque" identiques
        if random.random() < 0.3:
            duplicate['Prenom'] = duplicate['Prenom'].upper() if duplicate['Prenom'] else None
        data.append(duplicate)
    
    df = pd.DataFrame(data)
    print(f"  ‚úÖ Dataset final: {len(df):,} lignes")
    return df

def generate_consumption_data(city, size, population_ids):
    """G√©n√©rer des donn√©es de consommation √©nerg√©tique."""
    
    print(f"‚ö° G√©n√©ration de {size:,} relev√©s de consommation pour {city}...")
    
    data = []
    
    # Cr√©er une correspondance adresse -> ID pour coh√©rence
    if city.lower() == "paris":
        rues_list = RUES_PARIS
        codes_postaux = CODES_POSTAUX_PARIS
        id_offset = 0
    else:
        rues_list = RUES_EVRY
        codes_postaux = [91000]
        id_offset = 100000
    
    for i in range(1, size + 1):
        id_adr = id_offset + i
        
        # Num√©ro de rue avec quelques valeurs manquantes (2%)
        n = random.randint(1, 250) if random.random() > 0.02 else None
        
        # Nom de rue
        nom_rue = random.choice(rues_list)
        
        # Code postal
        code_postal = random.choice(codes_postaux)
        
        # Consommation avec distribution r√©aliste et valeurs aberrantes
        base_consumption = np.random.normal(18, 5)  # Moyenne 18 kWh/jour, √©cart-type 5
        
        # Ajouter de la variabilit√© saisonni√®re
        seasonal_factor = 1 + 0.3 * np.sin(2 * np.pi * random.random())
        consumption = base_consumption * seasonal_factor
        
        # Valeurs aberrantes (1%)
        if random.random() < 0.01:
            consumption = random.choice([random.uniform(0, 2), random.uniform(80, 150)])
        
        # Valeurs n√©gatives impossibles (0.5%)
        if random.random() < 0.005:
            consumption = -abs(consumption)
        
        # Valeurs manquantes (2.5%)
        if random.random() < 0.025:
            consumption = None
        else:
            consumption = round(consumption, 1)
        
        data.append({
            'ID_Adr': id_adr,
            'N': n,
            'Nom_Rue': nom_rue,
            'Code_Postal': code_postal,
            'NB_KW_Jour': consumption
        })
        
        if i % 15000 == 0:
            print(f"  ‚úì {i:,} relev√©s g√©n√©r√©s...")
    
    # Ajouter des doublons (2%)
    duplicates_count = int(size * 0.02)
    print(f"  üîÑ Ajout de {duplicates_count:,} doublons...")
    
    for _ in range(duplicates_count):
        original_row = random.choice(data)
        data.append(original_row.copy())
    
    df = pd.DataFrame(data)
    print(f"  ‚úÖ Dataset final: {len(df):,} lignes")
    return df

def generate_csp_data():
    """G√©n√©rer la table des cat√©gories socio-professionnelles."""
    
    print("üë• G√©n√©ration des cat√©gories socio-professionnelles...")
    
    # Donn√©es r√©alistes fran√ßaises
    csp_data = [
        {"ID_CSP": 1, "Desc": "Agriculteurs exploitants", "Salaire_Moyen": 25000, "Salaire_Min": 15000, "Salaire_Max": 45000},
        {"ID_CSP": 2, "Desc": "Artisans, commer√ßants et chefs d'entreprise", "Salaire_Moyen": 45000, "Salaire_Min": 20000, "Salaire_Max": 120000},
        {"ID_CSP": 3, "Desc": "Cadres et professions intellectuelles sup√©rieures", "Salaire_Moyen": 65000, "Salaire_Min": 40000, "Salaire_Max": 150000},
        {"ID_CSP": 4, "Desc": "Professions interm√©diaires", "Salaire_Moyen": 35000, "Salaire_Min": 25000, "Salaire_Max": 50000},
        {"ID_CSP": 5, "Desc": "Employ√©s", "Salaire_Moyen": 28000, "Salaire_Min": 20000, "Salaire_Max": 40000},
        {"ID_CSP": 6, "Desc": "Ouvriers", "Salaire_Moyen": 25000, "Salaire_Min": 18000, "Salaire_Max": 35000},
        {"ID_CSP": 7, "Desc": "Retrait√©s", "Salaire_Moyen": 18000, "Salaire_Min": 8000, "Salaire_Max": 35000},
        {"ID_CSP": 8, "Desc": "Autres personnes sans activit√© professionnelle", "Salaire_Moyen": 12000, "Salaire_Min": 0, "Salaire_Max": 25000}
    ]
    
    df = pd.DataFrame(csp_data)
    print(f"  ‚úÖ {len(df)} cat√©gories CSP g√©n√©r√©es")
    return df

def generate_iris_data():
    """G√©n√©rer la table IRIS (zones g√©ographiques)."""
    
    print("üó∫Ô∏è  G√©n√©ration des zones IRIS...")
    
    data = []
    
    # IRIS Paris
    for i in range(1, IRIS_ZONES_PARIS + 1):
        arrondissement = random.choice(CODES_POSTAUX_PARIS)
        data.append({
            'ID_Rue': i,
            'ID_Ville': 'Paris',
            'ID_IRIS': f'IRIS_{arrondissement}_{i:03d}'
        })
    
    # IRIS √âvry
    for i in range(1, IRIS_ZONES_EVRY + 1):
        data.append({
            'ID_Rue': 100000 + i,
            'ID_Ville': 'Evry',
            'ID_IRIS': f'IRIS_91000_{i:03d}'
        })
    
    df = pd.DataFrame(data)
    print(f"  ‚úÖ {len(df)} zones IRIS g√©n√©r√©es ({IRIS_ZONES_PARIS} Paris + {IRIS_ZONES_EVRY} √âvry)")
    return df

def generate_all_datasets():
    """G√©n√©rer tous les datasets en grande quantit√©."""
    
    print("üöÄ G√âN√âRATION DE DONN√âES SYNTH√âTIQUES EN GRANDE QUANTIT√â")
    print("=" * 60)
    print(f"Configuration:")
    print(f"  - Population Paris: {POPULATION_SIZE_PARIS:,} habitants")
    print(f"  - Population √âvry: {POPULATION_SIZE_EVRY:,} habitants") 
    print(f"  - Consommation Paris: {CONSUMPTION_RECORDS_PARIS:,} relev√©s")
    print(f"  - Consommation √âvry: {CONSUMPTION_RECORDS_EVRY:,} relev√©s")
    print(f"  - Zones IRIS: {IRIS_ZONES_PARIS + IRIS_ZONES_EVRY} total")
    print()
    
    # Cr√©er le dossier sources s'il n'existe pas
    sources_dir = "sources"
    if not os.path.exists(sources_dir):
        os.makedirs(sources_dir)
        print(f"üìÅ Dossier {sources_dir} cr√©√©")
    
    # 1. Population Paris
    pop_paris = generate_population_data("Paris", POPULATION_SIZE_PARIS)
    pop_paris.to_csv(f"{sources_dir}/population_paris.csv", index=False)
    print(f"üíæ Sauvegard√©: {sources_dir}/population_paris.csv")
    print()
    
    # 2. Population √âvry
    pop_evry = generate_population_data("√âvry", POPULATION_SIZE_EVRY)
    pop_evry.to_csv(f"{sources_dir}/population_evry.csv", index=False)
    print(f"üíæ Sauvegard√©: {sources_dir}/population_evry.csv")
    print()
    
    # 3. Consommation Paris
    conso_paris = generate_consumption_data("Paris", CONSUMPTION_RECORDS_PARIS, pop_paris['ID_Personne'].tolist())
    conso_paris.to_csv(f"{sources_dir}/consommation_paris.csv", index=False)
    print(f"üíæ Sauvegard√©: {sources_dir}/consommation_paris.csv")
    print()
    
    # 4. Consommation √âvry
    conso_evry = generate_consumption_data("√âvry", CONSUMPTION_RECORDS_EVRY, pop_evry['ID_Personne'].tolist())
    conso_evry.to_csv(f"{sources_dir}/consommation_evry.csv", index=False)
    print(f"üíæ Sauvegard√©: {sources_dir}/consommation_evry.csv")
    print()
    
    # 5. CSP
    csp = generate_csp_data()
    csp.to_csv(f"{sources_dir}/csp.csv", index=False)
    print(f"üíæ Sauvegard√©: {sources_dir}/csp.csv")
    print()
    
    # 6. IRIS
    iris = generate_iris_data()
    iris.to_csv(f"{sources_dir}/iris.csv", index=False)
    print(f"üíæ Sauvegard√©: {sources_dir}/iris.csv")
    print()
    
    # Statistiques finales
    total_rows = len(pop_paris) + len(pop_evry) + len(conso_paris) + len(conso_evry) + len(csp) + len(iris)
    print("üìä R√âSUM√â DE LA G√âN√âRATION")
    print("-" * 40)
    print(f"Population Paris:     {len(pop_paris):8,} lignes")
    print(f"Population √âvry:      {len(pop_evry):8,} lignes")
    print(f"Consommation Paris:   {len(conso_paris):8,} lignes")
    print(f"Consommation √âvry:    {len(conso_evry):8,} lignes")
    print(f"CSP:                  {len(csp):8,} lignes")
    print(f"IRIS:                 {len(iris):8,} lignes")
    print("-" * 40)
    print(f"TOTAL:                {total_rows:8,} lignes")
    print()
    
    # Calculer la taille des fichiers
    total_size_mb = 0
    for filename in os.listdir(sources_dir):
        if filename.endswith('.csv'):
            filepath = os.path.join(sources_dir, filename)
            size_mb = os.path.getsize(filepath) / (1024 * 1024)
            total_size_mb += size_mb
            print(f"{filename:25} : {size_mb:6.1f} MB")
    
    print(f"{'TAILLE TOTALE':25} : {total_size_mb:6.1f} MB")
    print()
    print("‚úÖ G√©n√©ration termin√©e avec succ√®s!")
    print("üîç Les donn√©es incluent des probl√®mes de qualit√© intentionnels:")
    print("   - Valeurs manquantes (1-3%)")
    print("   - Doublons (2-3%)")
    print("   - Formats incoh√©rents (codes CSP)")
    print("   - Valeurs aberrantes (consommation)")
    print("   - Codifications mixtes (texte/num√©rique)")

if __name__ == "__main__":
    # Permettre la personnalisation via arguments ou variables d'environnement
    import sys
    
    if len(sys.argv) > 1:
        try:
            scale_factor = float(sys.argv[1])
            POPULATION_SIZE_PARIS = int(POPULATION_SIZE_PARIS * scale_factor)
            POPULATION_SIZE_EVRY = int(POPULATION_SIZE_EVRY * scale_factor)
            CONSUMPTION_RECORDS_PARIS = int(CONSUMPTION_RECORDS_PARIS * scale_factor)
            CONSUMPTION_RECORDS_EVRY = int(CONSUMPTION_RECORDS_EVRY * scale_factor)
            print(f"üîß Facteur d'√©chelle appliqu√©: {scale_factor}x")
        except ValueError:
            print("‚ö†Ô∏è  Facteur d'√©chelle invalide, utilisation des valeurs par d√©faut")
    
    generate_all_datasets()