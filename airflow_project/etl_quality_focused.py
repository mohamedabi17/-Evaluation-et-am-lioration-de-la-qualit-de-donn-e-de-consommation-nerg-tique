#!/usr/bin/env python3
"""
üéØ ETL SIMPLIFI√â - Focus sur l'am√©lioration de qualit√© avec seuil 99%
√âvite les probl√®mes de jointure et se concentre sur la qualit√©
"""

import os
import sys
import pandas as pd
import json
from datetime import datetime
from pathlib import Path

# Ajouter le r√©pertoire utils au path
sys.path.append('utils')

from quality_checks import generate_quality_report, create_quality_visualizations
from data_quality_improver import (
    DataQualityImprover,
    create_improvement_config_population,
    create_improvement_config_consommation
)

# Configuration
SOURCES_PATH = "sources"
OUTPUT_PATH = "output"
QUALITY_REPORTS_PATH = "quality_reports" 
VISUALIZATIONS_PATH = "visualizations"
QUALITY_THRESHOLD = 99.0  # Seuil d'acceptabilit√© √† 99%

class SimplifiedETL:
    """ETL simplifi√© focus qualit√©."""
    
    def __init__(self):
        self.create_directories()
        self.execution_log = []
        self.start_time = datetime.now()
    
    def create_directories(self):
        """Cr√©er les dossiers de sortie."""
        for path in [OUTPUT_PATH, QUALITY_REPORTS_PATH, VISUALIZATIONS_PATH]:
            Path(path).mkdir(exist_ok=True)
        print("üìÅ Dossiers de sortie cr√©√©s")
    
    def log_step(self, message):
        """Logger une √©tape."""
        timestamp = datetime.now()
        print(f"‚úÖ {message} - {timestamp.strftime('%H:%M:%S')}")
        self.execution_log.append({
            'message': message,
            'timestamp': timestamp.isoformat()
        })
    
    def process_source(self, source_name):
        """Traiter une source de donn√©es compl√®tement."""
        
        print(f"\nüîÑ TRAITEMENT: {source_name.upper()}")
        print("=" * 50)
        
        # 1. Extraction
        file_path = f"{SOURCES_PATH}/{source_name}.csv"
        if not os.path.exists(file_path):
            print(f"‚ùå Fichier non trouv√©: {file_path}")
            return None
        
        df_original = pd.read_csv(file_path)
        print(f"üìä Donn√©es extraites: {len(df_original):,} lignes √ó {len(df_original.columns)} colonnes")
        
        # 2. √âvaluation qualit√© AVANT
        print("\nüîç √âVALUATION QUALIT√â INITIALE")
        print("-" * 35)
        
        report_before_path = f"{QUALITY_REPORTS_PATH}/{source_name}_before_quality.json"
        report_before = generate_quality_report(df_original, f"{source_name}_before", report_before_path)
        
        score_before = report_before['quality_score']['overall_quality_score']
        completeness_before = report_before['quality_score']['completeness_score']
        uniqueness_before = report_before['quality_score']['uniqueness_score']
        
        print(f"   üéØ Score global: {score_before:.2f}%")
        print(f"   ‚úÖ Compl√©tude: {completeness_before:.2f}%")
        print(f"   üîÑ Unicit√©: {uniqueness_before:.2f}%")
        
        # Analyse des probl√®mes
        problems = []
        for col, info in report_before['completeness'].items():
            if info['missing_count'] > 0:
                problems.append(f"{col}: {info['missing_count']} manquantes")
        
        if report_before['duplicates']['duplicate_count'] > 0:
            problems.append(f"Doublons: {report_before['duplicates']['duplicate_count']}")
        
        if problems:
            print(f"   ‚ö†Ô∏è  Probl√®mes d√©tect√©s: {', '.join(problems)}")
        
        # 3. D√©cision d'am√©lioration
        needs_improvement = score_before < QUALITY_THRESHOLD
        gap = QUALITY_THRESHOLD - score_before if needs_improvement else 0
        
        print(f"\nüéØ √âVALUATION SEUIL ({QUALITY_THRESHOLD}%)")
        print("-" * 30)
        
        if needs_improvement:
            print(f"   ‚ùå INSUFFISANT: {score_before:.2f}% < {QUALITY_THRESHOLD}%")
            print(f"   üìâ √âcart: -{gap:.2f} points")
            print("   üßπ Am√©lioration requise")
        else:
            print(f"   ‚úÖ CONFORME: {score_before:.2f}% ‚â• {QUALITY_THRESHOLD}%")
            print("   üéâ Qualit√© excellente")
        
        # 4. Am√©lioration (si n√©cessaire)
        if needs_improvement:
            print(f"\nüßπ AM√âLIORATION DE LA QUALIT√â")
            print("-" * 35)
            
            df_improved = self.improve_data_quality(df_original, source_name)
            
            # √âvaluation qualit√© APR√àS
            print(f"\nüîç √âVALUATION QUALIT√â FINALE")
            print("-" * 30)
            
            report_after_path = f"{QUALITY_REPORTS_PATH}/{source_name}_after_quality.json"
            report_after = generate_quality_report(df_improved, f"{source_name}_after", report_after_path)
            
            score_after = report_after['quality_score']['overall_quality_score']
            completeness_after = report_after['quality_score']['completeness_score']
            uniqueness_after = report_after['quality_score']['uniqueness_score']
            
            print(f"   üéØ Score global: {score_after:.2f}%")
            print(f"   ‚úÖ Compl√©tude: {completeness_after:.2f}%")
            print(f"   üîÑ Unicit√©: {uniqueness_after:.2f}%")
            
            # Calcul de l'am√©lioration
            improvement = score_after - score_before
            improvement_pct = (improvement / score_before) * 100 if score_before > 0 else 0
            
            print(f"\nüìà AM√âLIORATION R√âALIS√âE")
            print("-" * 28)
            print(f"   üìä Gain: +{improvement:.2f} points ({improvement_pct:+.1f}%)")
            
            # Validation finale
            meets_threshold = score_after >= QUALITY_THRESHOLD
            final_gap = QUALITY_THRESHOLD - score_after if not meets_threshold else 0
            
            if meets_threshold:
                print(f"   ‚úÖ SUCC√àS: {score_after:.2f}% ‚â• {QUALITY_THRESHOLD}%")
                print("   üéâ Objectif qualit√© atteint!")
            else:
                print(f"   ‚ö†Ô∏è  PARTIEL: {score_after:.2f}% < {QUALITY_THRESHOLD}%")
                print(f"   üìâ √âcart restant: -{final_gap:.2f} points")
            
            # Sauvegarder les donn√©es am√©lior√©es
            output_file = f"{OUTPUT_PATH}/{source_name}_improved.csv"
            df_improved.to_csv(output_file, index=False)
            print(f"   üíæ Sauvegard√©: {output_file}")
            
            return {
                'source_name': source_name,
                'original_rows': len(df_original),
                'final_rows': len(df_improved),
                'score_before': score_before,
                'score_after': score_after,
                'improvement': improvement,
                'meets_threshold': meets_threshold,
                'file_saved': output_file
            }
        
        else:
            # Pas d'am√©lioration n√©cessaire
            output_file = f"{OUTPUT_PATH}/{source_name}_validated.csv"
            df_original.to_csv(output_file, index=False)
            print(f"   üíæ Sauvegard√© (sans modification): {output_file}")
            
            return {
                'source_name': source_name,
                'original_rows': len(df_original),
                'final_rows': len(df_original),
                'score_before': score_before,
                'score_after': score_before,
                'improvement': 0,
                'meets_threshold': True,
                'file_saved': output_file
            }
    
    def improve_data_quality(self, df, source_name):
        """Am√©liorer la qualit√© des donn√©es."""
        
        improver = DataQualityImprover()
        
        # Configuration selon le type
        if 'population' in source_name:
            config = create_improvement_config_population()
        else:
            config = create_improvement_config_consommation()
        
        df_improved = df.copy()
        
        # √âtape 1: Suppression des doublons
        print("   1Ô∏è‚É£ Suppression des doublons...")
        duplicates_before = len(df_improved)
        df_improved = improver.remove_duplicates(df_improved)
        duplicates_removed = duplicates_before - len(df_improved)
        print(f"      ‚úÖ {duplicates_removed} doublons supprim√©s")
        
        # √âtape 2: Am√©lioration de la compl√©tude
        print("   2Ô∏è‚É£ Comblement des valeurs manquantes...")
        missing_before = df_improved.isnull().sum().sum()
        df_improved = improver.improve_completeness(df_improved, config['completeness_strategies'])
        missing_after = df_improved.isnull().sum().sum()
        print(f"      ‚úÖ {missing_before - missing_after} valeurs manquantes combl√©es")
        
        # √âtape 3: Standardisation des formats
        print("   3Ô∏è‚É£ Standardisation des formats...")
        df_improved = improver.standardize_format(df_improved, config['format_rules'])
        print(f"      ‚úÖ {len(config['format_rules'])} colonnes format√©es")
        
        # √âtape 4: Normalisation de la codification (si applicable)
        if 'codification_rules' in config and config['codification_rules']:
            print("   4Ô∏è‚É£ Normalisation de la codification...")
            df_improved = improver.normalize_codification(df_improved, config['codification_rules'])
            print(f"      ‚úÖ {len(config['codification_rules'])} colonnes codifi√©es")
        
        # √âtape 5: Application des r√®gles m√©tier
        print("   5Ô∏è‚É£ Application des r√®gles m√©tier...")
        df_improved = improver.apply_business_rules(df_improved, config['business_rules'])
        print(f"      ‚úÖ {len(config['business_rules'])} r√®gles appliqu√©es")
        
        # R√©sum√© des am√©liorations
        improvement_summary = improver.get_improvement_summary()
        total_actions = sum(improvement_summary['by_category'].values())
        
        print(f"\n   üìä ACTIONS TOTALES: {total_actions}")
        for category, count in improvement_summary['by_category'].items():
            print(f"      ‚Ä¢ {category}: {count}")
        
        return df_improved

def main():
    """Fonction principale."""
    
    print("üéØ ETL QUALIT√â DES DONN√âES - SEUIL 99%")
    print("=" * 60)
    print(f"Objectif: Atteindre {QUALITY_THRESHOLD}% de qualit√© sur toutes les sources")
    print()
    
    # V√©rifier les sources
    sources_dir = Path(SOURCES_PATH)
    if not sources_dir.exists():
        print(f"‚ùå Dossier '{SOURCES_PATH}' non trouv√©!")
        return
    
    # Sources √† traiter
    sources = ['population_paris', 'population_evry', 'consommation_paris', 'consommation_evry']
    available_sources = []
    
    for source in sources:
        file_path = sources_dir / f"{source}.csv"
        if file_path.exists():
            available_sources.append(source)
        else:
            print(f"‚ö†Ô∏è  Source manquante: {source}")
    
    if not available_sources:
        print("‚ùå Aucune source de donn√©es trouv√©e!")
        return
    
    print(f"üìã {len(available_sources)} sources √† traiter: {', '.join(available_sources)}")
    
    # Traiter chaque source
    etl = SimplifiedETL()
    results = []
    
    for source in available_sources:
        result = etl.process_source(source)
        if result:
            results.append(result)
    
    # R√©sum√© global
    if results:
        print(f"\nüìä R√âSUM√â GLOBAL")
        print("=" * 40)
        
        total_sources = len(results)
        conforming_sources = sum(1 for r in results if r['meets_threshold'])
        avg_improvement = sum(r['improvement'] for r in results) / total_sources
        total_rows_processed = sum(r['final_rows'] for r in results)
        
        print(f"   üìã Sources trait√©es: {total_sources}")
        print(f"   ‚úÖ Sources conformes (‚â•{QUALITY_THRESHOLD}%): {conforming_sources}/{total_sources}")
        print(f"   üìà Am√©lioration moyenne: +{avg_improvement:.2f} points")
        print(f"   üìä Lignes trait√©es: {total_rows_processed:,}")
        
        print(f"\n   üìä D√âTAIL PAR SOURCE:")
        for result in results:
            status = "‚úÖ" if result['meets_threshold'] else "‚ùå"
            print(f"      {status} {result['source_name']}: {result['score_before']:.1f}% ‚Üí {result['score_after']:.1f}% (+{result['improvement']:.1f})")
        
        # Statut final
        print(f"\nüéØ STATUT FINAL")
        print("-" * 20)
        
        if conforming_sources == total_sources:
            print(f"   üéâ SUCC√àS COMPLET!")
            print(f"   ‚úÖ Toutes les sources atteignent {QUALITY_THRESHOLD}%")
            print("   üèÜ Objectif qualit√© atteint")
        else:
            non_conforming = total_sources - conforming_sources
            print(f"   ‚ö†Ô∏è  SUCC√àS PARTIEL")
            print(f"   ‚ùå {non_conforming} source(s) sous le seuil")
            print("   üîß Optimisations suppl√©mentaires recommand√©es")
        
        print(f"\nüìÅ Fichiers cr√©√©s dans '{OUTPUT_PATH}/':")
        for result in results:
            file_name = Path(result['file_saved']).name
            print(f"   üìÑ {file_name}")
    
    print(f"\n‚úÖ ETL termin√©!")

if __name__ == "__main__":
    main()